# TinyLLaMA LoRA Fine-Tuning Project

## Project Overview
This project demonstrates the fine-tuning of a **TinyLLaMA 1.1B Chat model** using **LoRA (Low-Rank Adaptation)** and **4-bit quantization** to perform tasks such as **text-to-SQL** and **code generation**. The main goal is to adapt a pre-trained causal language model to specific datasets while keeping memory usage low and training efficient.

---

## Base Model
We use the pre-trained model from HuggingFace:

